{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory --> C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\research\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\configs\\cfgs.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "print(f\"Current Working Directory --> {os.getcwd()}\")\n",
    "#Add one directory above research\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\")) # Get the parent directory\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from configs import cfgs  # Absolute import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SweetViz Version : 2.3.1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import zscore\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, Dropdown\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "import sweetviz as sv\n",
    "print(\"SweetViz Version : {}\".format(sv.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cfgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions used for plots (histograms, scatter plots and correlation matrices)\n",
    "\n",
    "def histograms(df, selected_uid):\n",
    "    # Filter the DataFrame based on 'uid'\n",
    "    uid_data = df[df.index == selected_uid]\n",
    "\n",
    "    columns_to_plot = np.random.choice(df.columns, size=20, replace=False) # To print all features put this --> [col for col in df.columns]\n",
    "    \n",
    "    num_cols = 5\n",
    "    num_rows = int(np.ceil(len(columns_to_plot) / num_cols))\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 3 * num_rows)) \n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Plot histograms for each acoustic feature\n",
    "    for idx, col in enumerate(columns_to_plot):\n",
    "        sns.histplot(uid_data[col], ax=axes[idx])\n",
    "        axes[idx].set_title(f\"{col}\", fontsize=9)\n",
    "        axes[idx].set_xlabel('')\n",
    "        axes[idx].set_ylabel('Frequency', fontsize=8)\n",
    "\n",
    "    # Remove empty axes\n",
    "    for idx in range(len(columns_to_plot), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "\n",
    "    plt.tight_layout(pad=1.5)\n",
    "    plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    plt.show()\n",
    "\n",
    "def scatter_plot(df, selected_index):\n",
    "    # Filter data for the selected index\n",
    "    uid_data = df[df.index == selected_index]\n",
    "    \n",
    "    columns_to_plot = np.random.choice(df.columns, size=20, replace=False) # To print all features put this --> [col for col in df.columns]\n",
    "    \n",
    "    num_cols = 5  \n",
    "    num_rows = int(np.ceil(len(columns_to_plot) / num_cols))\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 3 * num_rows))\n",
    "    axes = axes.flatten()  \n",
    "    \n",
    "    # Generate scatterplots\n",
    "    for idx, col in enumerate(columns_to_plot):\n",
    "        sns.scatterplot(data=uid_data, x=range(len(uid_data)), y=uid_data[col], ax=axes[idx])\n",
    "        axes[idx].set_title(f\"{col}\", fontsize=9)\n",
    "        axes[idx].set_xlabel('Index')\n",
    "        axes[idx].set_ylabel('Value', fontsize=8)\n",
    "    \n",
    "    for idx in range(len(columns_to_plot), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "    \n",
    "    plt.tight_layout(pad=1.5)\n",
    "    plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    plt.show()\n",
    "\n",
    "def correlation_matrix(df, selected_index):\n",
    "    # Filter the DataFrame by the selected index\n",
    "    filtered_df = df[df.index == selected_index]\n",
    "    \n",
    "    # Check if there are enough rows for correlation\n",
    "    if filtered_df.shape[0] <= 1:\n",
    "        print(f\"Not enough data for index '{selected_index}' to calculate correlations.\")\n",
    "        return\n",
    "    \n",
    "    # Calculate the correlation matrix\n",
    "    correlation_matrix = filtered_df.corr()\n",
    "\n",
    "    plt.figure(figsize=(22, 22))  \n",
    "    sns.heatmap(\n",
    "        correlation_matrix, annot=False, cmap='coolwarm', center=0, \n",
    "        cbar=True, square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.75}\n",
    "    )\n",
    "    plt.title(f\"Correlation Matrix for Index '{selected_index}'\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def find_columns_with_high_missing_percentage(df, threshold=0.5, exclude_columns=None):\n",
    "  \"\"\"\n",
    "  Finds columns in a DataFrame with a missing value percentage exceeding a specified threshold,\n",
    "  optionally excluding specified columns from the check.\n",
    "\n",
    "  Args:\n",
    "    df: The pandas DataFrame to analyze.\n",
    "    threshold: The threshold for the missing value percentage (default: 0.7, which is 70%).\n",
    "    exclude_columns: A list of column names to exclude from the missing value check.  Defaults to None (no columns excluded).\n",
    "\n",
    "  Returns:\n",
    "    A list of column names that have a missing value percentage greater than the threshold,\n",
    "    excluding any columns specified in `exclude_columns`.  Returns an empty list if no\n",
    "    columns exceed the threshold after exclusion.\n",
    "  \"\"\"\n",
    "\n",
    "  # Create a copy of the DataFrame to avoid modifying the original.  This is IMPORTANT.\n",
    "  df_to_check = df.copy()\n",
    "\n",
    "  # Exclude specified columns, if any\n",
    "  if exclude_columns:\n",
    "    df_to_check = df_to_check.drop(columns=exclude_columns, errors='ignore')  # Use errors='ignore'\n",
    "\n",
    "  missing_percentages = df_to_check.isnull().sum() / len(df_to_check)\n",
    "  columns_to_drop = missing_percentages[missing_percentages > threshold].index.tolist()\n",
    "  return columns_to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT AND UNDERSTAND DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the code all the data is loaded:\n",
    "\n",
    "- _metadata.csv_: contains the demographics information (age and gender), dataset spit (train or test), has and file size.\n",
    "- _test_features.csv_: Test set.\n",
    "- _train_features.csv_: Train set\n",
    "- _train_labels.csv_: To Predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\dataset\\modified\n",
      "\n",
      "\n",
      "MetaData File Path --> C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\dataset\\modified\\metadata.csv\n",
      "\n",
      "\n",
      "Train Features File Path --> C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\dataset\\modified\\train_features.csv\n",
      "Train Labels File Path --> C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\dataset\\modified\\train_labels.csv\n",
      "\n",
      "\n",
      "Test Features File Path --> C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\dataset\\modified\\test_features.csv\n",
      "\n",
      "\n",
      "Submission File Path --> C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\dataset\\modified\\submission_format.csv\n"
     ]
    }
   ],
   "source": [
    "# Create a path object\n",
    "dataset_dir = cfgs[\"DATASET_DIR\"]\n",
    "dataset_path = Path(dataset_dir)\n",
    "print(f\"Dataset: {dataset_path}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# # Find all text files inside a directory\n",
    "# files = list(dataset_path.glob(\"*.csv\"))\n",
    "\n",
    "# Combining multiple paths\n",
    "path_metadata = dataset_path / \"metadata.csv\"\n",
    "path_trainfeatures = dataset_path / \"train_features.csv\"\n",
    "path_trainlabels = dataset_path / \"train_labels.csv\"\n",
    "path_testfeatures = dataset_path / \"test_features.csv\"\n",
    "path_submissionformat = dataset_path / \"submission_format.csv\"\n",
    "\n",
    "print(f\"MetaData File Path --> {path_metadata}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Train Features File Path --> {path_trainfeatures}\")\n",
    "print(f\"Train Labels File Path --> {path_trainlabels}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Test Features File Path --> {path_testfeatures}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Submission File Path --> {path_submissionformat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data as dataframe format\n",
    "# metadata       = pd.read_csv(path_metadata)\n",
    "# metadata.set_index('uid', inplace=True)\n",
    "\n",
    "train_features      = pd.read_csv(path_trainfeatures, encoding = 'utf8')\n",
    "train_labels        = pd.read_csv(path_trainlabels, encoding = 'utf8')\n",
    "\n",
    "test_features       = pd.read_csv(path_testfeatures, encoding = 'utf8')\n",
    "submission_format   = pd.read_csv(path_submissionformat, encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3276 entries, 0 to 3275\n",
      "Data columns (total 184 columns):\n",
      " #    Column             Non-Null Count  Dtype  \n",
      "---   ------             --------------  -----  \n",
      " 0    uid                3276 non-null   object \n",
      " 1    age_03             2240 non-null   object \n",
      " 2    urban_03           2242 non-null   object \n",
      " 3    married_03         2242 non-null   object \n",
      " 4    n_mar_03           2222 non-null   float64\n",
      " 5    edu_gru_03         2232 non-null   object \n",
      " 6    n_living_child_03  2230 non-null   object \n",
      " 7    migration_03       2241 non-null   float64\n",
      " 8    glob_hlth_03       2104 non-null   object \n",
      " 9    adl_dress_03       2105 non-null   float64\n",
      " 10   adl_walk_03        2235 non-null   float64\n",
      " 11   adl_bath_03        2235 non-null   float64\n",
      " 12   adl_eat_03         2234 non-null   float64\n",
      " 13   adl_bed_03         2235 non-null   float64\n",
      " 14   adl_toilet_03      2235 non-null   float64\n",
      " 15   n_adl_03           2234 non-null   float64\n",
      " 16   iadl_money_03      2105 non-null   float64\n",
      " 17   iadl_meds_03       2105 non-null   float64\n",
      " 18   iadl_shop_03       2105 non-null   float64\n",
      " 19   iadl_meals_03      2105 non-null   float64\n",
      " 20   n_iadl_03          2105 non-null   float64\n",
      " 21   depressed_03       2101 non-null   float64\n",
      " 22   hard_03            2104 non-null   float64\n",
      " 23   restless_03        2104 non-null   float64\n",
      " 24   happy_03           2098 non-null   float64\n",
      " 25   lonely_03          2104 non-null   float64\n",
      " 26   enjoy_03           2099 non-null   float64\n",
      " 27   sad_03             2105 non-null   float64\n",
      " 28   tired_03           2105 non-null   float64\n",
      " 29   energetic_03       2097 non-null   float64\n",
      " 30   n_depr_03          2100 non-null   float64\n",
      " 31   cesd_depressed_03  2100 non-null   float64\n",
      " 32   hypertension_03    2242 non-null   float64\n",
      " 33   diabetes_03        2242 non-null   float64\n",
      " 34   resp_ill_03        2242 non-null   float64\n",
      " 35   arthritis_03       2242 non-null   float64\n",
      " 36   hrt_attack_03      2241 non-null   float64\n",
      " 37   stroke_03          2242 non-null   float64\n",
      " 38   cancer_03          2242 non-null   float64\n",
      " 39   n_illnesses_03     2241 non-null   float64\n",
      " 40   bmi_03             1575 non-null   object \n",
      " 41   exer_3xwk_03       2105 non-null   float64\n",
      " 42   alcohol_03         2241 non-null   float64\n",
      " 43   tobacco_03         2241 non-null   float64\n",
      " 44   test_chol_03       2098 non-null   float64\n",
      " 45   test_tuber_03      2094 non-null   float64\n",
      " 46   test_diab_03       2103 non-null   float64\n",
      " 47   test_pres_03       2103 non-null   float64\n",
      " 48   hosp_03            2242 non-null   float64\n",
      " 49   visit_med_03       2238 non-null   float64\n",
      " 50   out_proc_03        2242 non-null   float64\n",
      " 51   visit_dental_03    2242 non-null   float64\n",
      " 52   imss_03            2242 non-null   float64\n",
      " 53   issste_03          2242 non-null   float64\n",
      " 54   pem_def_mar_03     2242 non-null   float64\n",
      " 55   insur_private_03   2242 non-null   float64\n",
      " 56   insur_other_03     2242 non-null   float64\n",
      " 57   insured_03         2242 non-null   float64\n",
      " 58   decis_famil_03     1555 non-null   object \n",
      " 59   decis_personal_03  2098 non-null   float64\n",
      " 60   employment_03      2240 non-null   object \n",
      " 61   age_12             3186 non-null   object \n",
      " 62   urban_12           3187 non-null   object \n",
      " 63   married_12         3187 non-null   object \n",
      " 64   n_mar_12           3160 non-null   float64\n",
      " 65   edu_gru_12         3176 non-null   object \n",
      " 66   n_living_child_12  3166 non-null   object \n",
      " 67   migration_12       3187 non-null   float64\n",
      " 68   glob_hlth_12       3060 non-null   object \n",
      " 69   adl_dress_12       3060 non-null   float64\n",
      " 70   adl_walk_12        3176 non-null   float64\n",
      " 71   adl_bath_12        3166 non-null   float64\n",
      " 72   adl_eat_12         3174 non-null   float64\n",
      " 73   adl_bed_12         3175 non-null   float64\n",
      " 74   adl_toilet_12      3175 non-null   float64\n",
      " 75   n_adl_12           3164 non-null   float64\n",
      " 76   iadl_money_12      3059 non-null   float64\n",
      " 77   iadl_meds_12       3059 non-null   float64\n",
      " 78   iadl_shop_12       3059 non-null   float64\n",
      " 79   iadl_meals_12      3059 non-null   float64\n",
      " 80   n_iadl_12          3058 non-null   float64\n",
      " 81   depressed_12       3054 non-null   float64\n",
      " 82   hard_12            3058 non-null   float64\n",
      " 83   restless_12        3057 non-null   float64\n",
      " 84   happy_12           3053 non-null   float64\n",
      " 85   lonely_12          3057 non-null   float64\n",
      " 86   enjoy_12           3055 non-null   float64\n",
      " 87   sad_12             3057 non-null   float64\n",
      " 88   tired_12           3059 non-null   float64\n",
      " 89   energetic_12       3058 non-null   float64\n",
      " 90   n_depr_12          3039 non-null   float64\n",
      " 91   cesd_depressed_12  3039 non-null   float64\n",
      " 92   hypertension_12    3178 non-null   float64\n",
      " 93   diabetes_12        3178 non-null   float64\n",
      " 94   resp_ill_12        3182 non-null   float64\n",
      " 95   arthritis_12       3178 non-null   float64\n",
      " 96   hrt_attack_12      3181 non-null   float64\n",
      " 97   stroke_12          3183 non-null   float64\n",
      " 98   cancer_12          3178 non-null   float64\n",
      " 99   n_illnesses_12     3158 non-null   float64\n",
      " 100  bmi_12             2838 non-null   object \n",
      " 101  exer_3xwk_12       3060 non-null   float64\n",
      " 102  alcohol_12         3187 non-null   float64\n",
      " 103  tobacco_12         3187 non-null   float64\n",
      " 104  test_chol_12       3051 non-null   float64\n",
      " 105  test_tuber_12      3022 non-null   float64\n",
      " 106  test_diab_12       3057 non-null   float64\n",
      " 107  test_pres_12       3057 non-null   float64\n",
      " 108  hosp_12            3187 non-null   float64\n",
      " 109  visit_med_12       3181 non-null   float64\n",
      " 110  out_proc_12        3186 non-null   float64\n",
      " 111  visit_dental_12    3181 non-null   float64\n",
      " 112  imss_12            3184 non-null   float64\n",
      " 113  issste_12          3185 non-null   float64\n",
      " 114  pem_def_mar_12     3187 non-null   float64\n",
      " 115  insur_private_12   3185 non-null   float64\n",
      " 116  insur_other_12     3183 non-null   float64\n",
      " 117  insured_12         3187 non-null   float64\n",
      " 118  decis_famil_12     2050 non-null   object \n",
      " 119  decis_personal_12  3051 non-null   object \n",
      " 120  employment_12      3187 non-null   object \n",
      " 121  vax_flu_12         3053 non-null   float64\n",
      " 122  vax_pneu_12        2985 non-null   float64\n",
      " 123  seg_pop_12         3187 non-null   float64\n",
      " 124  care_adult_12      3060 non-null   float64\n",
      " 125  care_child_12      3059 non-null   float64\n",
      " 126  volunteer_12       3057 non-null   float64\n",
      " 127  attends_class_12   3059 non-null   float64\n",
      " 128  attends_club_12    3060 non-null   float64\n",
      " 129  reads_12           3051 non-null   float64\n",
      " 130  games_12           3057 non-null   float64\n",
      " 131  table_games_12     3057 non-null   float64\n",
      " 132  comms_tel_comp_12  3058 non-null   float64\n",
      " 133  act_mant_12        3060 non-null   float64\n",
      " 134  tv_12              3060 non-null   float64\n",
      " 135  sewing_12          3060 non-null   float64\n",
      " 136  satis_ideal_12     2999 non-null   object \n",
      " 137  satis_excel_12     3037 non-null   object \n",
      " 138  satis_fine_12      3053 non-null   object \n",
      " 139  cosas_imp_12       3048 non-null   object \n",
      " 140  wouldnt_change_12  3028 non-null   object \n",
      " 141  memory_12          3031 non-null   object \n",
      " 142  ragender           3276 non-null   object \n",
      " 143  rameduc_m          2862 non-null   object \n",
      " 144  rafeduc_m          2774 non-null   object \n",
      " 145  sgender_03         1728 non-null   object \n",
      " 146  rjob_hrswk_03      1143 non-null   float64\n",
      " 147  rjlocc_m_03        311 non-null    object \n",
      " 148  rjob_end_03        339 non-null    float64\n",
      " 149  rjobend_reason_03  348 non-null    object \n",
      " 150  rearnings_03       2239 non-null   float64\n",
      " 151  searnings_03       1668 non-null   float64\n",
      " 152  hincome_03         2217 non-null   float64\n",
      " 153  hinc_business_03   2255 non-null   float64\n",
      " 154  hinc_rent_03       2255 non-null   float64\n",
      " 155  hinc_assets_03     2255 non-null   float64\n",
      " 156  hinc_cap_03        2255 non-null   float64\n",
      " 157  rinc_pension_03    2239 non-null   float64\n",
      " 158  sinc_pension_03    1668 non-null   float64\n",
      " 159  rrelgimp_03        2076 non-null   object \n",
      " 160  sgender_12         2092 non-null   object \n",
      " 161  rjob_hrswk_12      1260 non-null   float64\n",
      " 162  rjlocc_m_12        1706 non-null   object \n",
      " 163  rjob_end_12        473 non-null    float64\n",
      " 164  rjobend_reason_12  488 non-null    object \n",
      " 165  rearnings_12       3187 non-null   float64\n",
      " 166  searnings_12       2091 non-null   float64\n",
      " 167  hincome_12         3138 non-null   float64\n",
      " 168  hinc_business_12   3187 non-null   float64\n",
      " 169  hinc_rent_12       3187 non-null   float64\n",
      " 170  hinc_assets_12     3187 non-null   float64\n",
      " 171  hinc_cap_12        3187 non-null   float64\n",
      " 172  rinc_pension_12    3187 non-null   float64\n",
      " 173  sinc_pension_12    2091 non-null   float64\n",
      " 174  rrelgimp_12        3054 non-null   object \n",
      " 175  rrfcntx_m_12       3051 non-null   object \n",
      " 176  rsocact_m_12       3060 non-null   object \n",
      " 177  rrelgwk_12         3058 non-null   object \n",
      " 178  a16a_12            24 non-null     float64\n",
      " 179  a21_12             42 non-null     float64\n",
      " 180  a22_12             36 non-null     object \n",
      " 181  a33b_12            42 non-null     object \n",
      " 182  a34_12             2112 non-null   object \n",
      " 183  j11_12             3201 non-null   object \n",
      "dtypes: float64(140), object(44)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_features.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the training data we have 184 columns\n",
      "In the test data we have 184 columns\n"
     ]
    }
   ],
   "source": [
    "print(f\"In the training data we have \" + str(train_features.shape[1]) + \" columns\")\n",
    "print(f\"In the test data we have \" + str(test_features.shape[1]) + \" columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the training data we have 3276 unique patients and there are 3276 rows in the training data\n",
      "In the label data we have 3276 unique patients and there are 4343 rows in the training label data\n"
     ]
    }
   ],
   "source": [
    "print(f\"In the training data we have \" + str(train_features[\"uid\"].nunique()) + \" unique patients and there are \" + str(train_features.shape[0]) + \" rows in the training data\")\n",
    "print(f\"In the label data we have \" + str(train_labels[\"uid\"].nunique()) + \" unique patients and there are \" + str(train_labels.shape[0]) + \" rows in the training label data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are more rows in the label file than we have rows in the train features. This is because we want to estimate the composite score for 2016 (4 years in the future) and 2021 (9 years in the future) for some patients. This is also the case for the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the test data we have 819 unique patients and there are 819 rows in the test data\n",
      "In the label data we have 819 unique patients and there are 1105 rows in the test label data\n"
     ]
    }
   ],
   "source": [
    "print(f\"In the test data we have \" + str(test_features[\"uid\"].nunique()) + \" unique patients and there are \" + str(test_features.shape[0]) + \" rows in the test data\")\n",
    "print(f\"In the label data we have \" + str(submission_format[\"uid\"].nunique()) + \" unique patients and there are \" + str(submission_format.shape[0]) + \" rows in the test label data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uid              0\n",
       "age_03        1036\n",
       "urban_03      1034\n",
       "married_03    1034\n",
       "n_mar_03      1054\n",
       "              ... \n",
       "a21_12        3234\n",
       "a22_12        3240\n",
       "a33b_12       3234\n",
       "a34_12        1164\n",
       "j11_12          75\n",
       "Length: 184, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_missing = train_features.isnull().sum()\n",
    "has_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with more than 40% missing values: ['bmi_03', 'decis_famil_03', 'sgender_03', 'rjob_hrswk_03', 'rjlocc_m_03', 'rjob_end_03', 'rjobend_reason_03', 'searnings_03', 'sinc_pension_03', 'rjob_hrswk_12', 'rjlocc_m_12', 'rjob_end_12', 'rjobend_reason_12', 'a16a_12', 'a21_12', 'a22_12', 'a33b_12']\n",
      "Total Columns with more than 40% missing values: 17\n"
     ]
    }
   ],
   "source": [
    "columns_with_high_missing = find_columns_with_high_missing_percentage(train_features, threshold=0.40, exclude_columns=None)\n",
    "\n",
    "if columns_with_high_missing:\n",
    "    print(\"Columns with more than 40% missing values:\", columns_with_high_missing)\n",
    "    print(\"Total Columns with more than 40% missing values:\", len(columns_with_high_missing))\n",
    "else:\n",
    "    print(\"No columns have more than 40% missing values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with more than 50% missing values: ['bmi_03', 'decis_famil_03', 'rjob_hrswk_03', 'rjlocc_m_03', 'rjob_end_03', 'rjobend_reason_03', 'rjob_hrswk_12', 'rjob_end_12', 'rjobend_reason_12', 'a16a_12', 'a21_12', 'a22_12', 'a33b_12']\n",
      "Total Columns with 50% missing values: 13\n"
     ]
    }
   ],
   "source": [
    "columns_with_high_missing = find_columns_with_high_missing_percentage(train_features, threshold=0.50, exclude_columns=None)\n",
    "\n",
    "if columns_with_high_missing:\n",
    "    print(\"Columns with more than 50% missing values:\", columns_with_high_missing)\n",
    "    print(\"Total Columns with more than 50% missing values:\", len(columns_with_high_missing))\n",
    "else:\n",
    "    print(\"No columns have more than 50% missing values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with more than 60% missing values: ['rjob_hrswk_03', 'rjlocc_m_03', 'rjob_end_03', 'rjobend_reason_03', 'rjob_hrswk_12', 'rjob_end_12', 'rjobend_reason_12', 'a16a_12', 'a21_12', 'a22_12', 'a33b_12']\n",
      "Total Columns with 60% missing values: 11\n"
     ]
    }
   ],
   "source": [
    "columns_with_high_missing = find_columns_with_high_missing_percentage(train_features, threshold=0.60, exclude_columns=None)\n",
    "\n",
    "if columns_with_high_missing:\n",
    "    print(\"Columns with more than 60% missing values:\", columns_with_high_missing)\n",
    "    print(\"Total Columns with more than 60% missing values:\", len(columns_with_high_missing))\n",
    "else:\n",
    "    print(\"No columns have more than 60% missing values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with more than 70% missing values: ['rjlocc_m_03', 'rjob_end_03', 'rjobend_reason_03', 'rjob_end_12', 'rjobend_reason_12', 'a16a_12', 'a21_12', 'a22_12', 'a33b_12']\n",
      "Total Columns with 70% missing values: 9\n"
     ]
    }
   ],
   "source": [
    "columns_with_high_missing = find_columns_with_high_missing_percentage(train_features, threshold=0.70, exclude_columns=None)\n",
    "\n",
    "if columns_with_high_missing:\n",
    "    print(\"Columns with more than 70% missing values:\", columns_with_high_missing)\n",
    "    print(\"Total Columns with more than 70% missing values:\", len(columns_with_high_missing))\n",
    "else:\n",
    "    print(\"No columns have more than 70% missing values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "False    2209\n",
       "True     1067\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of patinents with composite score at both 2016 and 2021 in the training data\n",
    "(train_labels.groupby(\"uid\").count()[\"year\"] == 2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "False    533\n",
       "True     286\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of patinents we need to predict composite for both 2016 and 2021 in the test data\n",
    "(submission_format.groupby(\"uid\").count()[\"year\"] == 2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     182\n",
       "False      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many columns have at least one missing value (training data)\n",
    "(train_features.isna().sum() != 0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     182\n",
       "False      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many columns have at least one missing value (test data)\n",
    "(test_features.isna().sum() != 0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.45"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round((train_features.isna().sum().sum() / (train_features.shape[0]*train_features.shape[1]))*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total there are 22.45 % missing values in the training data\n"
     ]
    }
   ],
   "source": [
    "print(\"In total there are \" + str(round((train_features.isna().sum().sum() / (train_features.shape[0]*train_features.shape[1]))*100,2)) + \" % missing values in the training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total there are 21.92 % missing values in the test data\n"
     ]
    }
   ],
   "source": [
    "print(\"In total there are \" + str(round((test_features.isna().sum().sum() / (test_features.shape[0]*test_features.shape[1]))*100,2)) + \" % missing values in the test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate features where we need to estimate composite score for both 2016 and 2021 (training data)\n",
    "train_data = train_labels.merge(train_features, on=\"uid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uid', 'year', 'composite_score', 'age_03', 'urban_03', 'married_03',\n",
       "       'n_mar_03', 'edu_gru_03', 'n_living_child_03', 'migration_03',\n",
       "       ...\n",
       "       'rrelgimp_12', 'rrfcntx_m_12', 'rsocact_m_12', 'rrelgwk_12', 'a16a_12',\n",
       "       'a21_12', 'a22_12', 'a33b_12', 'a34_12', 'j11_12'],\n",
       "      dtype='object', length=186)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"pred_year\"] = train_data[\"year\"]-2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uid', 'year', 'composite_score', 'age_03', 'urban_03', 'married_03',\n",
       "       'n_mar_03', 'edu_gru_03', 'n_living_child_03', 'migration_03',\n",
       "       ...\n",
       "       'rrfcntx_m_12', 'rsocact_m_12', 'rrelgwk_12', 'a16a_12', 'a21_12',\n",
       "       'a22_12', 'a33b_12', 'a34_12', 'j11_12', 'pred_year'],\n",
       "      dtype='object', length=187)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       9\n",
       "1       9\n",
       "2       4\n",
       "3       9\n",
       "4       9\n",
       "       ..\n",
       "4338    9\n",
       "4339    4\n",
       "4340    9\n",
       "4341    9\n",
       "4342    9\n",
       "Name: pred_year, Length: 4343, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.pred_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate features where we need to estimate composite score for both 2016 and 2021 (test data)\n",
    "aligned_test_features = submission_format[[\"uid\",\"year\"]].merge(test_features, on=\"uid\")\n",
    "aligned_test_features[\"pred_year\"] = aligned_test_features[\"year\"]-2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = train_data.drop(columns=['uid', 'year', 'composite_score'])\n",
    "y = train_data['composite_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_03</th>\n",
       "      <th>urban_03</th>\n",
       "      <th>married_03</th>\n",
       "      <th>n_mar_03</th>\n",
       "      <th>edu_gru_03</th>\n",
       "      <th>n_living_child_03</th>\n",
       "      <th>migration_03</th>\n",
       "      <th>glob_hlth_03</th>\n",
       "      <th>adl_dress_03</th>\n",
       "      <th>adl_walk_03</th>\n",
       "      <th>...</th>\n",
       "      <th>rrfcntx_m_12</th>\n",
       "      <th>rsocact_m_12</th>\n",
       "      <th>rrelgwk_12</th>\n",
       "      <th>a16a_12</th>\n",
       "      <th>a21_12</th>\n",
       "      <th>a22_12</th>\n",
       "      <th>a33b_12</th>\n",
       "      <th>a34_12</th>\n",
       "      <th>j11_12</th>\n",
       "      <th>pred_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>0.No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Concrete 2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>1.Almost every day</td>\n",
       "      <td>0.No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Concrete 2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.2 or 3 times a month</td>\n",
       "      <td>2.4 or more times a week</td>\n",
       "      <td>0.No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wood, mosaic, or other covering 1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.2 or 3 times a month</td>\n",
       "      <td>2.4 or more times a week</td>\n",
       "      <td>0.No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wood, mosaic, or other covering 1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. 50–59</td>\n",
       "      <td>1. 100,000+</td>\n",
       "      <td>3. Widowed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3. 7–9 years</td>\n",
       "      <td>1. 1 or 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4. Fair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.Once a week</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>1.Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No 2</td>\n",
       "      <td>Concrete 2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age_03     urban_03  married_03  n_mar_03    edu_gru_03  \\\n",
       "0       NaN          NaN         NaN       NaN           NaN   \n",
       "1       NaN          NaN         NaN       NaN           NaN   \n",
       "2       NaN          NaN         NaN       NaN           NaN   \n",
       "3       NaN          NaN         NaN       NaN           NaN   \n",
       "4  1. 50–59  1. 100,000+  3. Widowed       1.0  3. 7–9 years   \n",
       "\n",
       "  n_living_child_03  migration_03 glob_hlth_03  adl_dress_03  adl_walk_03  \\\n",
       "0               NaN           NaN          NaN           NaN          NaN   \n",
       "1               NaN           NaN          NaN           NaN          NaN   \n",
       "2               NaN           NaN          NaN           NaN          NaN   \n",
       "3               NaN           NaN          NaN           NaN          NaN   \n",
       "4         1. 1 or 2           0.0      4. Fair           0.0          0.0   \n",
       "\n",
       "   ...            rrfcntx_m_12              rsocact_m_12  rrelgwk_12  a16a_12  \\\n",
       "0  ...                 9.Never                   9.Never        0.No      NaN   \n",
       "1  ...                 9.Never        1.Almost every day        0.No      NaN   \n",
       "2  ...  6.2 or 3 times a month  2.4 or more times a week        0.No      NaN   \n",
       "3  ...  6.2 or 3 times a month  2.4 or more times a week        0.No      NaN   \n",
       "4  ...           4.Once a week                   9.Never       1.Yes      NaN   \n",
       "\n",
       "   a21_12  a22_12  a33b_12  a34_12                             j11_12  \\\n",
       "0     NaN     NaN      NaN     NaN                         Concrete 2   \n",
       "1     NaN     NaN      NaN     NaN                         Concrete 2   \n",
       "2     NaN     NaN      NaN     NaN  Wood, mosaic, or other covering 1   \n",
       "3     NaN     NaN      NaN     NaN  Wood, mosaic, or other covering 1   \n",
       "4     NaN     NaN      NaN    No 2                         Concrete 2   \n",
       "\n",
       "   pred_year  \n",
       "0          9  \n",
       "1          9  \n",
       "2          4  \n",
       "3          9  \n",
       "4          9  \n",
       "\n",
       "[5 rows x 184 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical and categorical columns\n",
    "num_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "cat_cols = X.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute training features\n",
    "X[num_cols] = num_imputer.fit_transform(X[num_cols])\n",
    "X[cat_cols] = cat_imputer.fit_transform(X[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encode categorical variables\n",
    "# label_encoders = {}\n",
    "# for col in cat_cols:\n",
    "#     le = LabelEncoder()\n",
    "#     X[col] = le.fit_transform(X[col])\n",
    "#     label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_03</th>\n",
       "      <th>urban_03</th>\n",
       "      <th>married_03</th>\n",
       "      <th>n_mar_03</th>\n",
       "      <th>edu_gru_03</th>\n",
       "      <th>n_living_child_03</th>\n",
       "      <th>migration_03</th>\n",
       "      <th>glob_hlth_03</th>\n",
       "      <th>adl_dress_03</th>\n",
       "      <th>adl_walk_03</th>\n",
       "      <th>...</th>\n",
       "      <th>rrfcntx_m_12</th>\n",
       "      <th>rsocact_m_12</th>\n",
       "      <th>rrelgwk_12</th>\n",
       "      <th>a16a_12</th>\n",
       "      <th>a21_12</th>\n",
       "      <th>a22_12</th>\n",
       "      <th>a33b_12</th>\n",
       "      <th>a34_12</th>\n",
       "      <th>j11_12</th>\n",
       "      <th>pred_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. 50–59</td>\n",
       "      <td>1. 100,000+</td>\n",
       "      <td>1. Married or in civil union</td>\n",
       "      <td>1.126879</td>\n",
       "      <td>1. 1–5 years</td>\n",
       "      <td>2. 3 or 4</td>\n",
       "      <td>0.099065</td>\n",
       "      <td>4. Fair</td>\n",
       "      <td>0.041514</td>\n",
       "      <td>0.017708</td>\n",
       "      <td>...</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>0.No</td>\n",
       "      <td>1974.911765</td>\n",
       "      <td>7.254545</td>\n",
       "      <td>Agriculture/ Animal breeding 01</td>\n",
       "      <td>Neither 3</td>\n",
       "      <td>No 2</td>\n",
       "      <td>Concrete 2</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1. 50–59</td>\n",
       "      <td>1. 100,000+</td>\n",
       "      <td>1. Married or in civil union</td>\n",
       "      <td>1.126879</td>\n",
       "      <td>1. 1–5 years</td>\n",
       "      <td>2. 3 or 4</td>\n",
       "      <td>0.099065</td>\n",
       "      <td>4. Fair</td>\n",
       "      <td>0.041514</td>\n",
       "      <td>0.017708</td>\n",
       "      <td>...</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>1.Almost every day</td>\n",
       "      <td>0.No</td>\n",
       "      <td>1974.911765</td>\n",
       "      <td>7.254545</td>\n",
       "      <td>Agriculture/ Animal breeding 01</td>\n",
       "      <td>Neither 3</td>\n",
       "      <td>No 2</td>\n",
       "      <td>Concrete 2</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1. 50–59</td>\n",
       "      <td>1. 100,000+</td>\n",
       "      <td>1. Married or in civil union</td>\n",
       "      <td>1.126879</td>\n",
       "      <td>1. 1–5 years</td>\n",
       "      <td>2. 3 or 4</td>\n",
       "      <td>0.099065</td>\n",
       "      <td>4. Fair</td>\n",
       "      <td>0.041514</td>\n",
       "      <td>0.017708</td>\n",
       "      <td>...</td>\n",
       "      <td>6.2 or 3 times a month</td>\n",
       "      <td>2.4 or more times a week</td>\n",
       "      <td>0.No</td>\n",
       "      <td>1974.911765</td>\n",
       "      <td>7.254545</td>\n",
       "      <td>Agriculture/ Animal breeding 01</td>\n",
       "      <td>Neither 3</td>\n",
       "      <td>No 2</td>\n",
       "      <td>Wood, mosaic, or other covering 1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1. 50–59</td>\n",
       "      <td>1. 100,000+</td>\n",
       "      <td>1. Married or in civil union</td>\n",
       "      <td>1.126879</td>\n",
       "      <td>1. 1–5 years</td>\n",
       "      <td>2. 3 or 4</td>\n",
       "      <td>0.099065</td>\n",
       "      <td>4. Fair</td>\n",
       "      <td>0.041514</td>\n",
       "      <td>0.017708</td>\n",
       "      <td>...</td>\n",
       "      <td>6.2 or 3 times a month</td>\n",
       "      <td>2.4 or more times a week</td>\n",
       "      <td>0.No</td>\n",
       "      <td>1974.911765</td>\n",
       "      <td>7.254545</td>\n",
       "      <td>Agriculture/ Animal breeding 01</td>\n",
       "      <td>Neither 3</td>\n",
       "      <td>No 2</td>\n",
       "      <td>Wood, mosaic, or other covering 1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. 50–59</td>\n",
       "      <td>1. 100,000+</td>\n",
       "      <td>3. Widowed</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3. 7–9 years</td>\n",
       "      <td>1. 1 or 2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4. Fair</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.Once a week</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>1.Yes</td>\n",
       "      <td>1974.911765</td>\n",
       "      <td>7.254545</td>\n",
       "      <td>Agriculture/ Animal breeding 01</td>\n",
       "      <td>Neither 3</td>\n",
       "      <td>No 2</td>\n",
       "      <td>Concrete 2</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age_03     urban_03                    married_03  n_mar_03  \\\n",
       "0  1. 50–59  1. 100,000+  1. Married or in civil union  1.126879   \n",
       "1  1. 50–59  1. 100,000+  1. Married or in civil union  1.126879   \n",
       "2  1. 50–59  1. 100,000+  1. Married or in civil union  1.126879   \n",
       "3  1. 50–59  1. 100,000+  1. Married or in civil union  1.126879   \n",
       "4  1. 50–59  1. 100,000+                    3. Widowed  1.000000   \n",
       "\n",
       "     edu_gru_03 n_living_child_03  migration_03 glob_hlth_03  adl_dress_03  \\\n",
       "0  1. 1–5 years         2. 3 or 4      0.099065      4. Fair      0.041514   \n",
       "1  1. 1–5 years         2. 3 or 4      0.099065      4. Fair      0.041514   \n",
       "2  1. 1–5 years         2. 3 or 4      0.099065      4. Fair      0.041514   \n",
       "3  1. 1–5 years         2. 3 or 4      0.099065      4. Fair      0.041514   \n",
       "4  3. 7–9 years         1. 1 or 2      0.000000      4. Fair      0.000000   \n",
       "\n",
       "   adl_walk_03  ...            rrfcntx_m_12              rsocact_m_12  \\\n",
       "0     0.017708  ...                 9.Never                   9.Never   \n",
       "1     0.017708  ...                 9.Never        1.Almost every day   \n",
       "2     0.017708  ...  6.2 or 3 times a month  2.4 or more times a week   \n",
       "3     0.017708  ...  6.2 or 3 times a month  2.4 or more times a week   \n",
       "4     0.000000  ...           4.Once a week                   9.Never   \n",
       "\n",
       "   rrelgwk_12      a16a_12    a21_12                           a22_12  \\\n",
       "0        0.No  1974.911765  7.254545  Agriculture/ Animal breeding 01   \n",
       "1        0.No  1974.911765  7.254545  Agriculture/ Animal breeding 01   \n",
       "2        0.No  1974.911765  7.254545  Agriculture/ Animal breeding 01   \n",
       "3        0.No  1974.911765  7.254545  Agriculture/ Animal breeding 01   \n",
       "4       1.Yes  1974.911765  7.254545  Agriculture/ Animal breeding 01   \n",
       "\n",
       "     a33b_12  a34_12                             j11_12  pred_year  \n",
       "0  Neither 3    No 2                         Concrete 2        9.0  \n",
       "1  Neither 3    No 2                         Concrete 2        9.0  \n",
       "2  Neither 3    No 2  Wood, mosaic, or other covering 1        4.0  \n",
       "3  Neither 3    No 2  Wood, mosaic, or other covering 1        9.0  \n",
       "4  Neither 3    No 2                         Concrete 2        9.0  \n",
       "\n",
       "[5 rows x 184 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    175\n",
       "1    206\n",
       "Name: composite_score, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55328d0aa864463aabc2fb6cf9df0c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |                                       | [  0%]   00:00 -> (? le…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n",
      "C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\.venv\\Lib\\site-packages\\sweetviz\\graph_associations.py:219: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_dataframe[feature] = pd.Series(dtype=float)\n"
     ]
    }
   ],
   "source": [
    "# analyzing the dataset\n",
    "report = sv.analyze(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA Report: C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\visualization\\alzheimer_eda.html\n",
      "\n",
      "\n",
      "Report C:\\Users\\maz\\dev\\Projects\\proj_alzheimer_research\\visualization\\alzheimer_eda.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "# show the report in a form of an HTML file\n",
    "VIS_DIR = cfgs[\"VISUALIZATION_DIR\"]\n",
    "path_vis = Path(VIS_DIR)\n",
    "path_visReport = path_vis / \"alzheimer_eda.html\"\n",
    "print(f\"EDA Report: {path_visReport}\")\n",
    "print(\"\\n\")\n",
    "report.show_html(path_visReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Proj Alzheimer Research Kernel",
   "language": "python",
   "name": "proj-alzheimer-research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
